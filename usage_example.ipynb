{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 34.87189483642578\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Eagle_Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    Eagle_Loss is a custom loss function designed for image reconstruction tasks, with an emphasis on preserving\n",
    "    textures and edges in the reconstructed images. It operates by analyzing the variance of image gradients within\n",
    "    patches of the image, and by computing loss in the frequency domain using a high-pass filter.\n",
    "\n",
    "    Parameters:\n",
    "        patch_size (int): Defines the size of the patches used to calculate the variance in gradients.\n",
    "        cutoff (float): The cutoff frequency for the high-pass filter used in gaussian high-pass filtering.\n",
    "        cpu (bool): Determines whether the kernels are stored on the CPU (if True) or on CUDA (if False).\n",
    "\n",
    "    Methods:\n",
    "        forward(output, target): Calculates the Eagle loss between the output and target images.\n",
    "        calculate_gradient(img): Computes the x and y gradients of an image using the Scharr filters.\n",
    "        calculate_patch_loss(output_gradient, target_gradient): Measures the loss based on the variance of\n",
    "            gradients within the image patches.\n",
    "        gaussian_highpass_weights2d(size): Generates the weights for high-pass filtering in the frequency domain.\n",
    "        fft_loss(pred, gt): Calculates the loss in the frequency domain using the high-pass filter.\n",
    "\n",
    "    Example Usage:\n",
    "        eagle_loss = Eagle_Loss(patch_size=3)\n",
    "        loss = eagle_loss(output_image, target_image)\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size, cpu=False, cutoff=0.5):\n",
    "        super(Eagle_Loss, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() and not cpu else 'cpu')\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "        # Scharr kernel for the gradient map calculation\n",
    "        kernel_values = [[-3, 0, 3], [-10, 0, 10], [-3, 0, 3]]\n",
    "        self.kernel_x = nn.Parameter(\n",
    "            torch.tensor(kernel_values, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(self.device),\n",
    "            requires_grad=False)\n",
    "        self.kernel_y = nn.Parameter(\n",
    "            torch.tensor(kernel_values, dtype=torch.float32).t().unsqueeze(0).unsqueeze(0).to(self.device),\n",
    "            requires_grad=False)\n",
    "\n",
    "        # Operation for unfolding image into non-overlapping patches\n",
    "        self.unfold = nn.Unfold(kernel_size=self.patch_size, stride=self.patch_size).to(self.device)\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        output, target = output.to(self.device), target.to(self.device)\n",
    "        if output.size(1) != 1 or target.size(1) != 1:\n",
    "            raise ValueError(\"Input 'output' and 'target' should be grayscale\")\n",
    "\n",
    "        # Gradient maps calculation\n",
    "        gx_output, gy_output = self.calculate_gradient(output)\n",
    "        gx_target, gy_target = self.calculate_gradient(target)\n",
    "\n",
    "        # Unfolding and variance calculation\n",
    "        eagle_loss = self.calculate_patch_loss(gx_output, gx_target) + \\\n",
    "                     self.calculate_patch_loss(gy_output, gy_target)\n",
    "\n",
    "        return eagle_loss\n",
    "\n",
    "    def calculate_gradient(self, img):\n",
    "        img = img.to(self.device)\n",
    "        gx = F.conv2d(img, self.kernel_x, padding=1, groups=img.shape[1])\n",
    "        gy = F.conv2d(img, self.kernel_y, padding=1, groups=img.shape[1])\n",
    "        return gx, gy\n",
    "\n",
    "    def calculate_patch_loss(self, output_gradient, target_gradient):\n",
    "        output_gradient, target_gradient = output_gradient.to(self.device), target_gradient.to(self.device)\n",
    "        batch_size = output_gradient.size(0)\n",
    "        num_channels = output_gradient.size(1)\n",
    "        patch_size_squared = self.patch_size * self.patch_size\n",
    "        output_patches = self.unfold(output_gradient).view(batch_size, num_channels, patch_size_squared, -1)\n",
    "        target_patches = self.unfold(target_gradient).view(batch_size, num_channels, patch_size_squared, -1)\n",
    "        var_output = torch.var(output_patches, dim=2, keepdim=True)\n",
    "        var_target = torch.var(target_patches, dim=2, keepdim=True)\n",
    "\n",
    "        shape0, shape1 = output_gradient.shape[-2] // self.patch_size, output_gradient.shape[-1] // self.patch_size\n",
    "        return self.fft_loss(var_target.view(batch_size, num_channels, shape0, shape1), var_output.view(batch_size, num_channels, shape0, shape1))\n",
    "\n",
    "    def gaussian_highpass_weights2d(self, size):\n",
    "        freq_x = torch.fft.fftfreq(size[0]).reshape(-1, 1).repeat(1, size[1]).to(self.device)\n",
    "        freq_y = torch.fft.fftfreq(size[1]).reshape(1, -1).repeat(size[0], 1).to(self.device)\n",
    "\n",
    "        freq_mag = torch.sqrt(freq_x ** 2 + freq_y ** 2)\n",
    "        weights = torch.exp(-0.5 * ((freq_mag - self.cutoff) ** 2))\n",
    "        return 1 - weights  # Inverted for high pass\n",
    "\n",
    "    def fft_loss(self, pred, gt):\n",
    "        pred, gt = pred.to(self.device), gt.to(self.device)\n",
    "        pred_fft = torch.fft.fft2(pred)\n",
    "        gt_fft = torch.fft.fft2(gt)\n",
    "        pred_mag = torch.sqrt(pred_fft.real ** 2 + pred_fft.imag ** 2)\n",
    "        gt_mag = torch.sqrt(gt_fft.real ** 2 + gt_fft.imag ** 2)\n",
    "\n",
    "        weights = self.gaussian_highpass_weights2d(pred.size()[2:]).to(pred.device)\n",
    "        weighted_pred_mag = weights * pred_mag\n",
    "        weighted_gt_mag = weights * gt_mag\n",
    "\n",
    "        return F.l1_loss(weighted_pred_mag, weighted_gt_mag)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    criterion = Eagle_Loss(patch_size=3)\n",
    "    output_image = torch.rand(16, 1, 512, 512)\n",
    "    target_image = torch.rand(16, 1, 512, 512)\n",
    "    loss = criterion(output_image, target_image)\n",
    "    print(\"Loss:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
